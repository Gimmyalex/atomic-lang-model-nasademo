#!/usr/bin/env python3
"""
Tiny Probabilistic Language Model
=================================

A minimal next-token language model that extends recursive grammar with probabilities.
Fits comfortably in a single file with only standard library dependencies.

Features:
- Probabilistic CFG with weighted productions
- Monte Carlo next-token prediction
- Recursive grammar generation
- ~120 lines, standard library only
"""

import random
from collections import defaultdict
from typing import List, Tuple, Dict, Optional

# Probabilistic grammar rules with weights
PG_RULES = {
    'S': [
        (1.0, ['DP', 'VP']),
    ],
    'DP': [
        (0.7, ['D', 'NP']),
        (0.3, ['D', 'N']),
    ],
    'NP': [
        (0.6, ['N']),
        (0.4, ['N', 'CP']),
    ],
    'VP': [
        (0.5, ['V']),
        (0.3, ['V', 'DP']),
        (0.2, ['V', 'VP']),
    ],
    'CP': [
        (1.0, ['C', 'S']),
    ],
    'D': [
        (0.7, ['the']),
        (0.3, ['a']),
    ],
    'N': [
        (0.4, ['student']),
        (0.3, ['teacher']),
        (0.2, ['book']),
        (0.1, ['class']),
    ],
    'V': [
        (0.4, ['left']),
        (0.3, ['smiled']),
        (0.2, ['praised']),
        (0.1, ['arrived']),
    ],
    'C': [
        (0.7, ['who']),
        (0.3, ['that']),
    ],
}

class ProbGrammar:
    """Probabilistic Context-Free Grammar for language modeling."""
    
    def __init__(self, rules: Dict[str, List[Tuple[float, List[str]]]] = None):
        """Initialize with grammar rules, normalizing probabilities."""
        self.rules = rules or PG_RULES
        self.normalize_rules()
        
    def normalize_rules(self):
        """Normalize rule probabilities to sum to 1.0."""
        for lhs, productions in self.rules.items():
            total = sum(weight for weight, _ in productions)
            if total > 0:
                self.rules[lhs] = [(weight/total, rhs) for weight, rhs in productions]
    
    def sample_expansion(self, symbol: str) -> List[str]:
        """Sample a production for the given non-terminal symbol."""
        if symbol not in self.rules:
            return [symbol]  # Terminal symbol
            
        productions = self.rules[symbol]
        weights = [w for w, _ in productions]
        chosen = random.choices(range(len(productions)), weights=weights)[0]
        return productions[chosen][1]
    
    def sample_sentence(self, start: str = 'S', max_depth: int = 10) -> str:
        """Generate a sentence by sampling from the grammar."""
        def expand(symbol: str, depth: int) -> List[str]:
            if depth >= max_depth or symbol not in self.rules:
                return [symbol] if symbol not in self.rules else []
                
            expansion = self.sample_expansion(symbol)
            result = []
            for sym in expansion:
                result.extend(expand(sym, depth + 1))
            return result
        
        tokens = expand(start, 0)
        return ' '.join(tokens)
    
    def predict_next(self, prefix: str, k: int = 1000) -> List[Tuple[str, float]]:
        """
        Predict next token probabilities given a prefix.
        
        Uses Monte Carlo sampling:
        1. Generate k sentences
        2. Keep those that start with the prefix
        3. Return empirical distribution of next tokens
        """
        prefix_tokens = prefix.strip().split()
        prefix_len = len(prefix_tokens)
        
        # Count next tokens after prefix
        next_token_counts = defaultdict(int)
        valid_samples = 0
        
        for _ in range(k):
            sentence = self.sample_sentence()
            tokens = sentence.split()
            
            # Check if sentence starts with prefix
            if len(tokens) > prefix_len and tokens[:prefix_len] == prefix_tokens:
                next_token = tokens[prefix_len]
                next_token_counts[next_token] += 1
                valid_samples += 1
        
        # Convert to probabilities
        if valid_samples == 0:
            return []
            
        predictions = [
            (token, count / valid_samples)
            for token, count in sorted(next_token_counts.items(), 
                                     key=lambda x: -x[1])
        ]
        
        return predictions
    
    def parse_sentence(self, sentence: str) -> bool:
        """
        Check if sentence can be generated by the grammar.
        Simple recognition - for full parsing use Earley or CYK.
        """
        # This is a simplified check - real implementation would use
        # proper parsing algorithm. For now, just verify tokens exist.
        tokens = sentence.strip().split()
        terminals = set()
        
        for _, productions in self.rules.items():
            for _, rhs in productions:
                for symbol in rhs:
                    if symbol not in self.rules:
                        terminals.add(symbol)
        
        return all(token in terminals for token in tokens)
    
    def get_rule_probability(self, lhs: str, rhs: List[str]) -> float:
        """Get the probability of a specific production rule."""
        if lhs not in self.rules:
            return 0.0
            
        for weight, production in self.rules[lhs]:
            if production == rhs:
                return weight
        return 0.0


def demo():
    """Demonstrate the probabilistic language model."""
    print("ü§ñ Tiny Probabilistic Language Model Demo")
    print("=" * 50)
    
    # Initialize model
    model = ProbGrammar()
    
    # Generate sample sentences
    print("\nüìù Generated sentences:")
    for i in range(5):
        sentence = model.sample_sentence()
        print(f"{i+1}. {sentence}")
    
    # Predict next tokens
    prefix = "the student"
    print(f"\nüîÆ Next token predictions for '{prefix}':")
    predictions = model.predict_next(prefix, k=3000)
    
    for token, prob in predictions[:5]:
        print(f"  '{token}': {prob:.3f}")
    
    # Show total prediction coverage
    total_prob = sum(prob for _, prob in predictions)
    print(f"\nTotal probability mass: {total_prob:.3f}")
    print(f"Unique continuations: {len(predictions)}")


if __name__ == "__main__":
    demo()